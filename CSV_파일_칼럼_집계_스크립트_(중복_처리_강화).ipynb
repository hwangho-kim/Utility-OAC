{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwangho-kim/Utility-OAC/blob/main/CSV_%ED%8C%8C%EC%9D%BC_%EC%B9%BC%EB%9F%BC_%EC%A7%91%EA%B3%84_%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8_(%EC%A4%91%EB%B3%B5_%EC%B2%98%EB%A6%AC_%EA%B0%95%ED%99%94).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "def process_csv_files_with_aggregation(input_folder, output_folder):\n",
        "    \"\"\"\n",
        "    지정된 폴더의 CSV 파일들을 읽어 특정 패턴의 칼럼들의 평균 또는 합계를 계산하고,\n",
        "    결과를 새로운 CSV 파일로 저장합니다.\n",
        "    '전력'이 포함된 칼럼 그룹은 합계를 계산하고 _SUM 접미사를 붙입니다.\n",
        "    숫자 접미사 패턴(_X, _X_Y)을 유연하게 처리합니다.\n",
        "    기존에 _AVG 또는 _SUM으로 끝나는 집계된 열이 있으면 해당 열을 사용하고,\n",
        "    관련 원본 열들의 재집계를 건너<0xEB><0><0xB5>니다.\n",
        "\n",
        "    Args:\n",
        "        input_folder (str): 입력 CSV 파일들이 있는 폴더 경로.\n",
        "        output_folder (str): 처리된 CSV 파일들을 저장할 폴더 경로.\n",
        "    \"\"\"\n",
        "    # 출력 폴더가 존재하지 않으면 생성합니다.\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "        print(f\"출력 폴더 '{output_folder}'를 생성했습니다.\")\n",
        "\n",
        "    # 집계 대상 칼럼을 식별하기 위한 정규 표현식입니다. (예: data_1, feature_4_10)\n",
        "    column_pattern = re.compile(r\"^(.*?)_(\\d+)(_\\d+)?$\")\n",
        "\n",
        "    # 입력 폴더 내의 모든 파일을 확인합니다.\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(\".csv\"):\n",
        "            input_file_path = os.path.join(input_folder, filename)\n",
        "            output_file_name = f\"{os.path.splitext(filename)[0]}_PROCESSED.csv\"\n",
        "            output_file_path = os.path.join(output_folder, output_file_name)\n",
        "\n",
        "            print(f\"파일 '{filename}' 처리 중...\")\n",
        "\n",
        "            try:\n",
        "                df = pd.read_csv(input_file_path)\n",
        "\n",
        "                if df.empty:\n",
        "                    print(f\"  파일 '{filename}'이 비어있습니다. 원본 내용 그대로 '{output_file_name}'으로 저장합니다.\")\n",
        "                    df.to_csv(output_file_path, index=False, encoding='utf-8-sig')\n",
        "                    continue\n",
        "\n",
        "                cols_to_aggregate_map = defaultdict(list)\n",
        "                original_cols_to_keep = []\n",
        "                # 이미 _AVG 또는 _SUM으로 끝나는 집계된 열의 기본 이름을 저장하는 세트\n",
        "                found_aggregated_bases = set()\n",
        "\n",
        "                # 1. 칼럼 분류: 기존 집계 열, 신규 집계 대상 원본 열, 기타 유지 열\n",
        "                for col in df.columns:\n",
        "                    is_col_handled_as_existing_aggregate = False\n",
        "                    # 칼럼이 이미 _AVG 또는 _SUM으로 끝나는지 확인\n",
        "                    if col.endswith('_AVG') or col.endswith('_SUM'):\n",
        "                        # 기본 이름 추출 (예: \"feature_AVG\" -> \"feature\")\n",
        "                        base_of_existing_aggregate = col.rsplit('_', 1)[0]\n",
        "                        found_aggregated_bases.add(base_of_existing_aggregate)\n",
        "                        original_cols_to_keep.append(col) # 기존 집계 열은 그대로 유지\n",
        "                        is_col_handled_as_existing_aggregate = True\n",
        "\n",
        "                    # 기존 집계 열이 아니라면, 패턴 매칭 시도\n",
        "                    if not is_col_handled_as_existing_aggregate:\n",
        "                        match = column_pattern.match(col)\n",
        "                        if match:\n",
        "                            # 집계 대상이 될 수 있는 원본 열 (예: data_1)\n",
        "                            base_name = match.group(1)\n",
        "                            cols_to_aggregate_map[base_name].append(col)\n",
        "                        else:\n",
        "                            # 기타 칼럼 (예: Timestamp, Notes 등)\n",
        "                            original_cols_to_keep.append(col)\n",
        "\n",
        "                # 최종 결과 데이터프레임 파트 초기화 (유지할 원본 칼럼들)\n",
        "                # df[original_cols_to_keep]가 비어있을 수도 있으므로 .copy() 주의\n",
        "                if original_cols_to_keep:\n",
        "                    result_df_parts = [df[original_cols_to_keep].copy()]\n",
        "                else:\n",
        "                    result_df_parts = []\n",
        "\n",
        "\n",
        "                # 2. 신규 집계 처리\n",
        "                if not cols_to_aggregate_map and not original_cols_to_keep : # 모든 칼럼이 비었을 경우\n",
        "                     print(f\"  파일 '{filename}'에 처리할 칼럼이 없습니다.\")\n",
        "                elif not cols_to_aggregate_map:\n",
        "                    print(f\"  파일 '{filename}'에서 신규 집계 대상 칼럼을 찾지 못했습니다. 기존 집계/원본 칼럼만 유지됩니다.\")\n",
        "\n",
        "                for base_name, related_cols in cols_to_aggregate_map.items():\n",
        "                    # 만약 이 base_name에 해당하는 기존 _AVG/_SUM 열이 이미 존재한다면, 신규 집계 건너뛰기\n",
        "                    if base_name in found_aggregated_bases:\n",
        "                        print(f\"  '{base_name}' 그룹에 대한 집계 건너뛰기: 이미 '{base_name}_AVG' 또는 '{base_name}_SUM'과 같은 집계된 열이 존재합니다.\")\n",
        "                        continue\n",
        "\n",
        "                    if related_cols:\n",
        "                        numeric_cols_df = df[related_cols].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "                        agg_col_name = \"\"\n",
        "                        agg_series = None\n",
        "\n",
        "                        if \"전력\" in base_name:\n",
        "                            agg_col_name = f\"{base_name}_SUM\"\n",
        "                            agg_series = numeric_cols_df.sum(axis=1, skipna=True)\n",
        "                            print(f\"  칼럼 그룹 '{base_name}' (칼럼: {related_cols})의 합계를 '{agg_col_name}'으로 계산했습니다.\")\n",
        "                        else:\n",
        "                            agg_col_name = f\"{base_name}_AVG\"\n",
        "                            agg_series = numeric_cols_df.mean(axis=1, skipna=True)\n",
        "                            print(f\"  칼럼 그룹 '{base_name}' (칼럼: {related_cols})의 평균을 '{agg_col_name}'으로 계산했습니다.\")\n",
        "\n",
        "                        if agg_series is not None:\n",
        "                            agg_series.name = agg_col_name\n",
        "                            result_df_parts.append(agg_series)\n",
        "\n",
        "                # 3. 최종 데이터프레임 생성\n",
        "                if not result_df_parts :\n",
        "                    final_df = pd.DataFrame() # 모든 파트가 비어있으면 빈 DF 생성\n",
        "                else:\n",
        "                    # 비어있지 않은 Series/DataFrame만 concat 대상으로 필터링\n",
        "                    valid_parts = [part for part in result_df_parts if not (isinstance(part, (pd.DataFrame, pd.Series)) and part.empty)]\n",
        "                    if not valid_parts: # 유효한 파트가 하나도 없으면\n",
        "                         final_df = pd.DataFrame()\n",
        "                    else:\n",
        "                        final_df = pd.concat(valid_parts, axis=1)\n",
        "\n",
        "                final_df.to_csv(output_file_path, index=False, encoding='utf-8-sig')\n",
        "                print(f\"  파일 '{filename}' 처리 완료. 저장 위치: '{output_file_path}'\")\n",
        "\n",
        "            except pd.errors.EmptyDataError:\n",
        "                print(f\"  파일 '{filename}'이 비어있거나 유효한 CSV 형식이 아닙니다. 건너<0xEB><0><0xB5>니다.\") # \"건너<0xEB><0><0xB5>니다\" -> \"건너뜁니다\"\n",
        "            except Exception as e:\n",
        "                print(f\"  파일 '{filename}' 처리 중 오류 발생: {e}\")\n",
        "    print(\"\\n모든 CSV 파일 처리가 완료되었습니다.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    input_directory = \"your_input_csv_folder_path\"\n",
        "    output_directory = \"your_output_csv_folder_path\"\n",
        "\n",
        "    if input_directory == \"your_input_csv_folder_path\" or \\\n",
        "       output_directory == \"your_output_csv_folder_path\":\n",
        "        print(\"스크립트 하단의 'input_directory'와 'output_directory' 변수에\\n\"\n",
        "              \"실제 폴더 경로를 입력한 후 다시 실행해주세요.\")\n",
        "    else:\n",
        "        process_csv_files_with_aggregation(input_directory, output_directory)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "BbcbfTmLDGTh"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}